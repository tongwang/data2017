{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More basic ETL\n",
    "\n",
    "This week we'll take a look at more ETL functions, building up a mini warehouse using Bikeshare and weather data.\n",
    "\n",
    "## Setup - install PostgreSQL (Optional)\n",
    "\n",
    "We are going to use [PostgreSQL](https://www.postgresql.org) 9.5 or later version this time. If you are using AWS EC2 instances based on our AMI, you can skip this section. If postgresql is not installed, follow the [instructions](https://www.postgresql.org/download/linux/) to install it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to connect to PostgreSQL, we need to make sure [ipython-sql](https://github.com/catherinedevlin/ipython-sql) and [psycopg2](https://github.com/psycopg/psycopg2) libraries are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze | grep 'ipython-sql\\|psycopg2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see something like this, you are all set:\n",
    "```\n",
    "ipython-sql==0.3.8\n",
    "psycopg2==2.6.2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - bikeshare data, again\n",
    "\n",
    "We'll download the same Bikeshare data you've worked with before, and we'll create some database tables and indexes more deliberately using PostgreSQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!createdb -U student week11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql postgresql://student@/week11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O 2017-Q1-trips.zip https://s3.amazonaws.com/capitalbikeshare-data/2017-Q1-cabi-trips-history-data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -o 2017-Q1-trips.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mv 2017-Q1-Trips-History-Data.csv 2017q1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l 2017q1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!csvcut -n 2017q1.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create table and import\n",
    "\n",
    "Given the volume of data here, let's go straight to pgsql to load the data.\n",
    "\n",
    "*Note* use `gshuf` if you're on a Mac, otherwise try `shuf`.  Same options should work for both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 10000 2017q1.csv | csvstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!shuf -n 10000 2017q1.csv | csvstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these values, I expect we can work with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS rides;\n",
    "CREATE TABLE rides (\n",
    "    duration_ms INTEGER,\n",
    "    start_date TIMESTAMP,\n",
    "    end_date TIMESTAMP,\n",
    "    start_station_id INTEGER,\n",
    "    start_station VARCHAR(64),\n",
    "    end_station_id INTEGER,\n",
    "    end_station VARCHAR(64),\n",
    "    bike_number CHAR(21),\n",
    "    member_type CHAR(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll load the data directly using `COPY` command.  Note that this **requires** the use of an absolute path, so adjust it to your location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "COPY rides FROM '/home/ubuntu/star-week1/2017q1.csv'\n",
    "CSV\n",
    "HEADER;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT COUNT(*) FROM rides;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM rides\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More ETL with SQL\n",
    "\n",
    "Today we'll extend previous week's examples of how to extract consistent sets of values out of your database.  \n",
    "\n",
    "First let's pick up where we left off, extracting simple details like station names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT DISTINCT start_station, start_station_id\n",
    "FROM rides\n",
    "ORDER BY start_station\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT DISTINCT end_station, end_station_id\n",
    "FROM rides\n",
    "ORDER BY end_station\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be sure we get them all, we need to combine them into a union set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT DISTINCT start_station AS station, start_station_id AS station_id FROM rides\n",
    "UNION\n",
    "SELECT DISTINCT end_station AS station, end_station_id AS station_id FROM rides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a new table to house the unique station names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS stations;\n",
    "CREATE TABLE stations (\n",
    "    key SERIAL PRIMARY KEY,\n",
    "    name VARCHAR(64),\n",
    "    station_key INTEGER\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "INSERT INTO stations (name, station_key)\n",
    "SELECT DISTINCT start_station AS station, start_station_id AS station_key FROM rides\n",
    "UNION\n",
    "SELECT DISTINCT end_station AS station, end_station_id AS station_key FROM rides;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM stations LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even add these new identifiers back to the original table now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "ALTER TABLE rides \n",
    "ADD COLUMN start_station_key INTEGER,\n",
    "ADD CONSTRAINT fk_start_station\n",
    "FOREIGN KEY (start_station_key)\n",
    "REFERENCES stations (key);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "UPDATE rides AS r\n",
    "SET start_station_key = s.key\n",
    "FROM stations AS s\n",
    "WHERE r.start_station = s.name;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "ALTER TABLE rides \n",
    "ADD COLUMN end_station_key INTEGER,\n",
    "ADD CONSTRAINT fk_end_station\n",
    "FOREIGN KEY (end_station_key)\n",
    "REFERENCES stations (key);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "UPDATE rides AS r\n",
    "SET end_station_key = s.key\n",
    "FROM stations AS s\n",
    "WHERE r.end_station = s.name;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM rides\n",
    "LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple address geocoding\n",
    "\n",
    "It feels like we should do a little more with the stations, doesn't it?  Let's see if we can geocode them using the [geocoder library](https://geocoder.readthedocs.io/). First let's install `geocoder` package: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo /home/ubuntu/.local/bin/pip install geocoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import geocoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connecting to the db from python\n",
    "\n",
    "Here we'll use a little python to update run geocoding queries and flesh out the data a bit more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "ALTER TABLE stations\n",
    "ADD COLUMN lat NUMERIC DEFAULT 0,\n",
    "ADD COLUMN lng NUMERIC DEFAULT 0;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the following code takes very long to finish. Please complete the following steps at home."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\"dbname='week11' user='student'\")\n",
    "c = conn.cursor()\n",
    "c.execute(\"SELECT key, name FROM stations ORDER BY key ASC\")\n",
    "rows = c.fetchall()\n",
    "for r in rows:\n",
    "    station_key, station_name = r\n",
    "    print('%s: %s' % (station_key, station_name))\n",
    "    g = geocoder.google('%s Washington DC' % station_name)\n",
    "    c.execute(\"UPDATE stations SET lat = (%s), lng = (%s) WHERE key = (%s)\", \n",
    "              (g.lat, g.lng, station_key))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT AVG(lat), MIN(lat), MAX(lat), STDDEV(lat) FROM stations;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM stations LIMIT 10 ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT COUNT(*) FROM stations WHERE lat IS NULL OR lng IS NULL;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it mostly worked.  It's a start, at least."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add more derived facts and dimensions\n",
    "\n",
    "Another useful step might be recording the minutes as a new column so we don't have to calculate from milliseconds every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "ALTER TABLE rides\n",
    "ADD COLUMN duration_min NUMERIC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "UPDATE rides\n",
    "SET duration_min = ROUND(CAST(duration_ms AS NUMERIC) / (1000 * 60), 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT duration_ms, duration_min FROM rides\n",
    "LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In data warehouse models and in statistical model feature engineering, it can be particularly useful to extract all kinds of parts of dates out into their own attributes.  You never know where you'll find significance.\n",
    "\n",
    "This kind of extraction is quite common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT DISTINCT TO_CHAR(start_date, 'YYYY-MM-DD HH24:00:00') AS hour,\n",
    "    TO_CHAR(start_date, 'YYYY-MM-DD') AS day, \n",
    "    TO_CHAR(start_date, 'YYYY') AS year,\n",
    "    TO_CHAR(start_date, 'MM') AS month_of_year,\n",
    "    TO_CHAR(start_date, 'DD') AS day_of_month,\n",
    "    TO_CHAR(start_date, 'Day') AS day_of_week_str,\n",
    "    TO_CHAR(start_date, 'D') AS day_of_week,\n",
    "    CASE WHEN CAST(TO_CHAR(start_date, 'D') AS INTEGER) >= 6 \n",
    "        THEN 1 \n",
    "        ELSE 0\n",
    "    END AS is_weekend,\n",
    "    CASE WHEN CAST(TO_CHAR(start_date, 'D') AS INTEGER) < 6 \n",
    "        THEN 1 \n",
    "        ELSE 0\n",
    "    END AS is_weekday,\n",
    "    TO_CHAR(start_date, 'HH24') AS hour_of_day,\n",
    "    TO_CHAR(start_date, 'Q') AS quarter\n",
    "FROM rides\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS hours;\n",
    "CREATE TABLE hours (\n",
    "    key SERIAL PRIMARY KEY,\n",
    "    hour CHAR(19),\n",
    "    day CHAR(10),\n",
    "    year INTEGER,\n",
    "    month_of_year INTEGER,\n",
    "    day_of_month INTEGER,\n",
    "    day_of_week_str CHAR(9),\n",
    "    day_of_week INTEGER,\n",
    "    is_weekend BOOLEAN,\n",
    "    is_weekday BOOLEAN,\n",
    "    hour_of_day INTEGER,\n",
    "    quarter INTEGER\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "INSERT INTO hours (hour, day, year, month_of_year, day_of_month, day_of_week_str, day_of_week,\n",
    "                  is_weekend, is_weekday, hour_of_day, quarter)\n",
    "SELECT DISTINCT TO_CHAR(start_date, 'YYYY-MM-DD HH24:00:00') AS hour,\n",
    "    TO_CHAR(start_date, 'YYYY-MM-DD') AS day, \n",
    "    CAST(TO_CHAR(start_date, 'YYYY') AS INTEGER) AS year,\n",
    "    CAST(TO_CHAR(start_date, 'MM') AS INTEGER) AS month_of_year,\n",
    "    CAST(TO_CHAR(start_date, 'DD') AS INTEGER) AS day_of_month,\n",
    "    TO_CHAR(start_date, 'Day') AS day_of_week_str,\n",
    "    CAST(TO_CHAR(start_date, 'D') AS INTEGER) AS day_of_week,\n",
    "    CASE WHEN CAST(TO_CHAR(start_date, 'D') AS INTEGER) IN (1, 7) \n",
    "        THEN TRUE\n",
    "        ELSE FALSE\n",
    "    END AS is_weekend,\n",
    "    CASE WHEN CAST(TO_CHAR(start_date, 'D') AS INTEGER) NOT IN (1, 7) \n",
    "        THEN TRUE\n",
    "        ELSE FALSE\n",
    "    END AS is_weekday,\n",
    "    CAST(TO_CHAR(start_date, 'HH24') AS INTEGER) AS hour_of_day,\n",
    "    CAST(TO_CHAR(start_date, 'Q') AS INTEGER) AS quarter\n",
    "FROM rides\n",
    "UNION\n",
    "SELECT DISTINCT TO_CHAR(end_date, 'YYYY-MM-DD HH24:00:00') AS hour,\n",
    "    TO_CHAR(end_date, 'YYYY-MM-DD') AS day, \n",
    "    CAST(TO_CHAR(end_date, 'YYYY') AS INTEGER) AS year,\n",
    "    CAST(TO_CHAR(end_date, 'MM') AS INTEGER) AS month_of_year,\n",
    "    CAST(TO_CHAR(end_date, 'DD') AS INTEGER) AS day_of_month,\n",
    "    TO_CHAR(end_date, 'Day') AS day_of_week_str,\n",
    "    CAST(TO_CHAR(end_date, 'D') AS INTEGER) AS day_of_week,\n",
    "    CASE WHEN CAST(TO_CHAR(end_date, 'D') AS INTEGER) IN (1, 7) \n",
    "        THEN TRUE\n",
    "        ELSE FALSE\n",
    "    END AS is_weekend,\n",
    "    CASE WHEN CAST(TO_CHAR(end_date, 'D') AS INTEGER) NOT IN (1, 7) \n",
    "        THEN TRUE\n",
    "        ELSE FALSE\n",
    "    END AS is_weekday,\n",
    "    CAST(TO_CHAR(end_date, 'HH24') AS INTEGER) AS hour_of_day,\n",
    "    CAST(TO_CHAR(end_date, 'Q') AS INTEGER) AS quarter\n",
    "FROM rides;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM hours\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's make sure we got that weekend bit right:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT DISTINCT day_of_week_str, day_of_week, is_weekend, is_weekday FROM hours;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "ALTER TABLE rides \n",
    "ADD COLUMN start_hour_key INTEGER,\n",
    "ADD CONSTRAINT fk_start_hour\n",
    "FOREIGN KEY (start_hour_key)\n",
    "REFERENCES hours (key);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "UPDATE rides AS r\n",
    "SET start_hour_key = h.key\n",
    "FROM hours AS h\n",
    "WHERE TO_CHAR(r.start_date, 'YYYY-MM-DD HH24:00:00') = h.hour;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "ALTER TABLE rides \n",
    "ADD COLUMN end_hour_key INTEGER,\n",
    "ADD CONSTRAINT fk_end_hour\n",
    "FOREIGN KEY (end_hour_key)\n",
    "REFERENCES hours (key);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "UPDATE rides AS r\n",
    "SET end_hour_key = h.key\n",
    "FROM hours AS h\n",
    "WHERE TO_CHAR(r.end_date, 'YYYY-MM-DD HH24:00:00') = h.hour;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT rides.start_date, rides.end_date, s_hours.hour AS start_hour, e_hours.hour AS end_hour\n",
    "FROM rides\n",
    "JOIN hours AS s_hours\n",
    "  ON s_hours.key = rides.start_hour_key\n",
    "JOIN hours AS e_hours\n",
    "  ON e_hours.key = rides.end_hour_key\n",
    "WHERE bike_number = 'W20893'\n",
    "ORDER BY rides.start_date\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to explore the data. Let's find out the number of trips for each day of the week:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT day_of_week_str, COUNT(*) count\n",
    "FROM rides, hours\n",
    "WHERE rides.start_hour_key = hours.key\n",
    "GROUP BY day_of_week_str, day_of_week\n",
    "ORDER BY day_of_week;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = _\n",
    "result.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding weather data\n",
    "\n",
    "An interesting dimension to the bikeshare history is weather - I know I don't mind riding in the rain, but I'm probably the only one.\n",
    "\n",
    "Weather Underground offers access to weather history data at links like https://www.wunderground.com/history/airport/KDCA/2017/1/18/DailyHistory.html?req_city=Washington&req_state=DC&req_statename=District+of+Columbia&reqdb.zip=20003&reqdb.magic=1&reqdb.wmo=99999.  \n",
    "\n",
    "You can also download data in CSV format. For example: https://www.wunderground.com/history/airport/KDCA/2017/1/18/DailyHistory.html?req_city=Washington&req_state=DC&req_statename=District+of+Columbia&reqdb.zip=20003&reqdb.magic=1&reqdb.wmo=99999&format=1\n",
    "\n",
    "Mmm, CSV.  We know what to do with CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from string import Template\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_template = Template('https://www.wunderground.com/history/airport/KDCA/$year/$month/$day/DailyHistory.html?req_city=Washington&req_state=DC&req_statename=District+of+Columbia&reqdb.zip=20003&reqdb.magic=1&reqdb.wmo=99999&format=1')\n",
    "print(url_template.substitute(year=2017, month=1, day=18))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write simple python code to download the weather data for the first quarter of 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "year = 2017\n",
    "for month in range(1, 4):\n",
    "    days = calendar.monthrange(year, month)[1]\n",
    "    for day in range(1, days+1):\n",
    "        r = requests.get(url_template.substitute(year=year, month=month, day=day))\n",
    "        print('Saving weather-%04d%02d%02d.csv' % (year, month, day))\n",
    "        open('weather-%04d%02d%02d.csv' % (year, month, day), 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively you can download these csv files as a zip file and unzip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O weather2017q1.csv.zip https://raw.githubusercontent.com/tongwang/data2017/master/lectures/star-week-01/weather2017q1.csv.zip\n",
    "!unzip -o weather2017q1.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head weather-20170125.csv | csvlook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something is not right! The header is missing and there is `<br />` at the end of each line. Let's look at the raw content of the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!head weather-20170125.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two issues:\n",
    "1. The first line is blank\n",
    "2. There are extra characters at the end of each line.\n",
    "\n",
    "Let's clean the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed 's/<br \\/>//g;/^$/d' weather-20170125.csv | head | csvlook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it looks much better! Apply the fix to all weather CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!for f in weather-2017*.csv; do sed -i 's/<br \\/>//g;/^$/d' ${f}; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And combine date based csv files into a single file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!csvstack weather-201701*.csv weather-201702*.csv weather-201703*.csv > weather-2017q1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!csvstat weather-2017q1.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've noticed special values such as `N/A`, `-` and `None`. We need to remove them so that they will be treated as NULL by the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!sed -i 's/,N\\/A,/,,/g;s/,-,/,,/g;;s/,None,/,,/g' weather-2017q1.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these values, I expect we can work with the following schema for weather. Note that the type for `time_utc` is `TIMESTAMPTZ`, which is the abbreviation for `timestamp with time zone`, a PostgreSQL specific type. We also add an attribute named `time`. We will use it to store local eastern time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS weather;\n",
    "CREATE TABLE weather (\n",
    "    key SERIAL PRIMARY KEY,\n",
    "    time_str VARCHAR(8),\n",
    "    temp NUMERIC,\n",
    "    dew_point NUMERIC,\n",
    "    humidity NUMERIC,\n",
    "    pressure NUMERIC,\n",
    "    visibility NUMERIC,\n",
    "    wind_dir VARCHAR(8),\n",
    "    wind_speed VARCHAR(10),\n",
    "    gust_speed NUMERIC,\n",
    "    precipitation NUMERIC,\n",
    "    events VARCHAR(50),\n",
    "    conditions VARCHAR(50),\n",
    "    wind_dir_degrees NUMERIC,\n",
    "    time_utc TIMESTAMPTZ,\n",
    "    time TIMESTAMP\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll load the data into PostgreSQL. Note that this requires the use of an absolute path, so adjust it to your location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "COPY weather \n",
    "(time_str, temp, dew_point, humidity, pressure, visibility, wind_dir, wind_speed, gust_speed, precipitation, events, conditions, wind_dir_degrees, time_utc)\n",
    "FROM '/home/ubuntu/star-week1/weather-2017q1.csv'\n",
    "CSV\n",
    "HEADER\n",
    "QUOTE '\"'\n",
    "DELIMITER ',';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * from weather LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to convert UTC time to EST or EDT. We know Daylight Saving Time started on Sunday, March 12, 2017, 2:00:00 am. The conversion takes two steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we convert UTC times to EST times and populate `time` attribute for all `time_utc` values before `2017-03-12 07:00:00+00:00`, which is Sunday, March 12, 2017, 2:00:00 am EST. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "UPDATE weather SET time = time_utc AT TIME ZONE 'EST'\n",
    "WHERE time_utc <= '2017-03-12 07:00:00+00:00';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we convert UTC times to EDT times and populate `time` attribute for all `time_utc` values after `2017-03-12 07:00:00+00:00`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "UPDATE weather SET time = time_utc AT TIME ZONE 'EDT'\n",
    "WHERE time_utc > '2017-03-12 07:00:00+00:00';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that time attributes look okay on March 12:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT time_str, time from weather \n",
    "WHERE TO_CHAR(time, 'YYYY-MM-DD') = '2017-03-12'\n",
    "ORDER BY time;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we add two foreign key columns (`start_weather_key` and `end_weather_key`) to the `rides` table that reference `weather` dimension table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "ALTER TABLE rides \n",
    "ADD COLUMN start_weather_key INTEGER,\n",
    "ADD CONSTRAINT fk_start_weather\n",
    "FOREIGN KEY (start_weather_key)\n",
    "REFERENCES weather (key);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "ALTER TABLE rides \n",
    "ADD COLUMN end_weather_key INTEGER,\n",
    "ADD CONSTRAINT fk_end_weather\n",
    "FOREIGN KEY (end_weather_key)\n",
    "REFERENCES weather (key);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "UPDATE rides AS r\n",
    "SET start_weather_key = w.key\n",
    "FROM weather AS w\n",
    "WHERE TO_CHAR(r.start_date, 'YYYY-MM-DD HH24') = TO_CHAR(w.time, 'YYYY-MM-DD HH24');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "UPDATE rides AS r\n",
    "SET end_weather_key = w.key\n",
    "FROM weather AS w\n",
    "WHERE TO_CHAR(r.end_date, 'YYYY-MM-DD HH24') = TO_CHAR(w.time, 'YYYY-MM-DD HH24');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some rides do not have weather captured because there are some missing hours in the weather data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT COUNT(*) FROM rides\n",
    "WHERE start_weather_key IS NULL;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT COUNT(*) FROM rides\n",
    "WHERE end_weather_key IS NULL;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find out the top 5 weather conditions that people ride bikeshare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT w.conditions, COUNT(*) count\n",
    "FROM rides\n",
    "JOIN weather AS w\n",
    "ON w.key = rides.start_weather_key\n",
    "GROUP BY w.conditions\n",
    "ORDER BY count DESC\n",
    "LIMIT 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = _\n",
    "result.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the top 10 weather conditions that people ride bikeshare the least often:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT w.conditions, COUNT(*) count\n",
    "FROM rides\n",
    "JOIN weather AS w\n",
    "ON w.key = rides.start_weather_key\n",
    "GROUP BY w.conditions\n",
    "ORDER BY count ASC\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = _\n",
    "result.bar()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
