{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More basic ETL\n",
    "\n",
    "This week we'll take a look at more ETL functions, building up a mini warehouse using Bikeshare and weather data.\n",
    "\n",
    "## Setup - bikeshare data, again\n",
    "\n",
    "We'll download the same Bikeshare data you've worked with before, and we'll create some database tables and indexes more deliberately using PostgreSQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: To use PostgreSQL on datanotebook.org, use the following steps.  If you are running the notebook elsewhere, adjust the `dbuser` username and host name as appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!echo 'redspot' | sudo -S service postgresql restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!createdb -U dbuser week7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%sql postgresql://dbuser@localhost:5432/week7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/gwsb-istm-6212-fall-2016/syllabus-and-schedule/master/projects/project-01/2016q1.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!unzip 2016q1.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!wc -l 2016q1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!csvcut -n 2016q1.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create table and import\n",
    "\n",
    "Given the volume of data here, let's go straight to pgsql to load the data.\n",
    "\n",
    "*Note* use `gshuf` if you're on a Mac, otherwise try `shuf`.  Same options should work for both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!shuf -n 10000 2016q1.csv | csvstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these values, I expect we can work with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS rides;\n",
    "CREATE TABLE rides (\n",
    "    duration_ms INTEGER,\n",
    "    start_date TIMESTAMP,\n",
    "    end_date TIMESTAMP,\n",
    "    start_station_id INTEGER,\n",
    "    start_station VARCHAR(64),\n",
    "    end_station_id INTEGER,\n",
    "    end_station VARCHAR(64),\n",
    "    bike_number CHAR(6),\n",
    "    member_type CHAR(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll load the data in more simply.  Note that this **requires** the use of an absolute path, so adjust it to your location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "COPY rides FROM '/home/jovyan/work/2016q1.csv'\n",
    "CSV\n",
    "HEADER\n",
    "QUOTE '\"'\n",
    "DELIMITER ',';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT COUNT(*) FROM rides;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing\n",
    "\n",
    "We know we'll need a few indexes, so let's go ahead and create them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP INDEX IF EXISTS idx_stations_member_type;\n",
    "CREATE INDEX idx_stations_member_type ON rides (start_station, end_station, member_type);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP INDEX IF EXISTS idx_start_stations;\n",
    "CREATE INDEX idx_start_stations ON rides (start_station);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP INDEX IF EXISTS idx_end_stations;\n",
    "CREATE INDEX idx_end_stations ON rides (end_station);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More ETL with SQL\n",
    "\n",
    "Today we'll extend last week's examples of how to extract consistent sets of values out of your database.  \n",
    "\n",
    "First let's pick up where we left off, extracting simple details like station names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT DISTINCT start_station, start_station_id\n",
    "FROM rides\n",
    "ORDER BY start_station\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT DISTINCT end_station, end_station_id\n",
    "FROM rides\n",
    "ORDER BY end_station\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be sure we get them all, we need to combine them into a union set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT station, station_id\n",
    "FROM (\n",
    "    SELECT DISTINCT start_station AS station, start_station_id AS station_id FROM rides\n",
    "    UNION\n",
    "    SELECT DISTINCT end_station AS station, end_station_id AS station_id FROM rides\n",
    "    ) AS d\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a new table to house the unique station names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS stations;\n",
    "CREATE TABLE stations (\n",
    "    id SERIAL,\n",
    "    name VARCHAR(64),\n",
    "    station_key INTEGER\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "INSERT INTO stations (name, station_key)\n",
    "SELECT station, station_key FROM (\n",
    "    SELECT DISTINCT start_station AS station, start_station_id AS station_key FROM rides\n",
    "    UNION\n",
    "    SELECT DISTINCT end_station AS station, end_station_id AS station_key FROM rides\n",
    ") AS d;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM stations LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even add these new identifiers back to the original table now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "ALTER TABLE rides \n",
    "ADD COLUMN start_station_nid INTEGER;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "UPDATE rides AS r\n",
    "SET start_station_nid = s.id\n",
    "FROM stations AS s\n",
    "WHERE r.start_station = s.name;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "ALTER TABLE rides \n",
    "ADD COLUMN end_station_nid INTEGER;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "UPDATE rides AS r\n",
    "SET end_station_nid = s.id\n",
    "FROM stations AS s\n",
    "WHERE r.end_station = s.name;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM rides\n",
    "LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple address geocoding\n",
    "\n",
    "It feels like we should do a little more with the stations, doesn't it?  Let's see if we can geocode them using the [geocoder library](https://geocoder.readthedocs.io/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install geocoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import geocoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to the db from python\n",
    "\n",
    "Here we'll use a little python to update run geocoding queries and flesh out the data a bit more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "ALTER TABLE stations\n",
    "ADD COLUMN lat NUMERIC DEFAULT 0,\n",
    "ADD COLUMN lng NUMERIC DEFAULT 0;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note* the specific user and host names are required at datanotebook.org.  If you're running this locally, you'll need to adjust your username/dbname/etc. as appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\"dbname='week7' user='dbuser' host='localhost'\")\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c.execute(\"SELECT id, name FROM stations ORDER BY id ASC\")\n",
    "rows = c.fetchall()\n",
    "for r in rows:\n",
    "    station_id, station_name = r\n",
    "    print('%s: %s' % (station_id, station_name))\n",
    "    g = geocoder.google('%s Washington DC' % station_name)\n",
    "    c.execute(\"UPDATE stations SET lat = (%s), lng = (%s) WHERE id = (%s)\", \n",
    "              (g.lat, g.lng, station_id))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT AVG(lat), MIN(lat), MAX(lat), STDDEV(lat) FROM stations LIMIT 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM stations LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT COUNT(*) FROM stations WHERE lat IS NULL OR lng IS NULL;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it mostly worked.  It's a start, at least."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving a transformation with every query\n",
    "\n",
    "Another useful step might be recording the minutes as a new column so we don't have to calculate from milliseconds every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "ALTER TABLE rides\n",
    "ADD COLUMN duration_min NUMERIC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "UPDATE rides\n",
    "SET duration_min = ROUND(CAST(duration_ms AS NUMERIC) / (1000 * 60), 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT duration_ms, duration_min FROM rides\n",
    "LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another valuable pattern is to use date functions to extract particular time intervals, such as months or days.  Every RDBMS has its own set of date functions, unfortunately you will likely just have to learn the ones used by the system in your environment.\n",
    "\n",
    "Read more in the [documentation for PostgreSQL date formatting](https://www.postgresql.org/docs/9.5/static/functions-formatting.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT EXTRACT(DAY FROM start_date), EXTRACT(MONTH FROM start_date), EXTRACT(YEAR FROM start_date)\n",
    "FROM rides\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In data warehouse models and in statistical model feature engineering, it can be particularly useful to extract all kinds of parts of dates out into variables.  You never know where you'll find significance.\n",
    "\n",
    "This kind of extraction is quite common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT TO_CHAR(start_date, 'YYYY-MM-DD') AS day_of_year, \n",
    "    TO_CHAR(start_date, 'YYYY') AS year,\n",
    "    TO_CHAR(start_date, 'MM') AS month,\n",
    "    TO_CHAR(start_date, 'DD') AS day,\n",
    "    TO_CHAR(start_date, 'Day') AS day_of_week_str,\n",
    "    TO_CHAR(start_date, 'D') AS day_of_week,\n",
    "    CASE WHEN CAST(TO_CHAR(start_date, 'D') AS INTEGER) >= 6 \n",
    "        THEN 1 \n",
    "        ELSE 0\n",
    "    END AS is_weekend,\n",
    "    CASE WHEN CAST(TO_CHAR(start_date, 'D') AS INTEGER) < 6 \n",
    "        THEN 1 \n",
    "        ELSE 0\n",
    "    END AS is_weekday,\n",
    "    TO_CHAR(start_date, 'HH24') AS hour_24,\n",
    "    TO_CHAR(start_date, 'Q') AS quarter\n",
    "FROM rides\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS days;\n",
    "CREATE TABLE days (\n",
    "    id SERIAL,\n",
    "    day_of_year CHAR(10),\n",
    "    year INTEGER,\n",
    "    month INTEGER,\n",
    "    day INTEGER,\n",
    "    day_of_week_str CHAR(9),\n",
    "    day_of_week INTEGER,\n",
    "    is_weekend BOOLEAN,\n",
    "    is_weekday BOOLEAN,\n",
    "    hour_24 INTEGER,\n",
    "    quarter INTEGER\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "INSERT INTO days (day_of_year, year, month, day, day_of_week_str, day_of_week,\n",
    "                  is_weekend, is_weekday, hour_24, quarter)\n",
    "SELECT DISTINCT TO_CHAR(start_date, 'YYYY-MM-DD') AS day_of_year, \n",
    "    CAST(TO_CHAR(start_date, 'YYYY') AS INTEGER) AS year,\n",
    "    CAST(TO_CHAR(start_date, 'MM') AS INTEGER) AS month,\n",
    "    CAST(TO_CHAR(start_date, 'DD') AS INTEGER) AS day,\n",
    "    TO_CHAR(start_date, 'Day') AS day_of_week_str,\n",
    "    CAST(TO_CHAR(start_date, 'D') AS INTEGER) AS day_of_week,\n",
    "    CASE WHEN CAST(TO_CHAR(start_date, 'D') AS INTEGER) IN (1, 7) \n",
    "        THEN TRUE\n",
    "        ELSE FALSE\n",
    "    END AS is_weekend,\n",
    "    CASE WHEN CAST(TO_CHAR(start_date, 'D') AS INTEGER) NOT IN (1, 7) \n",
    "        THEN TRUE\n",
    "        ELSE FALSE\n",
    "    END AS is_weekday,\n",
    "    CAST(TO_CHAR(start_date, 'HH24') AS INTEGER) AS hour_24,\n",
    "    CAST(TO_CHAR(start_date, 'Q') AS INTEGER) AS quarter\n",
    "FROM rides;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM days\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's make sure we got that weekend bit right:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT DISTINCT day_of_week_str, day_of_week, is_weekend, is_weekday FROM days;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Adding weather data\n",
    "\n",
    "An interesting dimension to the bikeshare history is weather - I know I don't like to ride in the rain.  I'm probably not the only one.\n",
    "\n",
    "Weather Underground offers access to weather history data at links like https://www.wunderground.com/history/airport/KDCA/2016/1/18/DailyHistory.html?req_city=Washington&req_state=DC&req_statename=District+of+Columbia&reqdb.zip=20003&reqdb.magic=1&reqdb.wmo=99999.  Note that at the bottom there is a link to a 'Comma Delimited File' at the bottom.  It leads to https://www.wunderground.com/history/airport/KDCA/2016/1/18/DailyHistory.html?req_city=Washington&req_state=DC&req_statename=District+of+Columbia&reqdb.zip=20003&reqdb.magic=1&reqdb.wmo=99999&format=1\n",
    "\n",
    "Mmm, CSV.  We know what to do with CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from string import Template\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url_template = Template('https://www.wunderground.com/history/airport/KDCA/2016/1/$day/DailyHistory.html?req_city=Washington&req_state=DC&req_statename=District+of+Columbia&reqdb.zip=20003&reqdb.magic=1&reqdb.wmo=99999&format=1')\n",
    "print(url_template.substitute(day=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for d in range(1, 32):\n",
    "    r = requests.get(url_template.substitute(day=d))\n",
    "    open('weather-201601%02d.csv' % d, 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!head weather-20160125.csv | csvlook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!csvstack weather-2016*.csv > weather-2016q1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!wc weather*.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next steps:\n",
    "\n",
    " * remove the trailing chars from each line\n",
    " * create weather and load data \n",
    " * relate weather data to `days` table somehow"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
